{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "366f1c05-88f9-4d92-8463-e04679589bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de04a6f4-0522-4223-89b7-b40ffe14441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\" , 'r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e64289-0951-4209-a50f-28ca17bc180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters is ::  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters is :: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172eea81-fc8c-4c62-89b2-69ac505216a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5425e6f6-8872-4dbb-9a53-d7aebd90b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0afbf156-6396-437b-9569-9cdf6d923a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda s: (''.join([itos[c] for c in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d78f4cbf-80dc-48bc-af8d-a9c35a63a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fd1af46-038b-4583-97b2-b1be5b5edbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4f24803-ded7-4c1f-87b6-2b6e792a4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation split\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5673e930-b696-465e-b681-536e21682be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "when input is tensor([24]) the target: 43\n",
      "when input is tensor([24, 43]) the target: 58\n",
      "when input is tensor([24, 43, 58]) the target: 5\n",
      "when input is tensor([24, 43, 58,  5]) the target: 57\n",
      "when input is tensor([24, 43, 58,  5, 57]) the target: 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]) the target: 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]) the target: 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) the target: 39\n",
      "when input is tensor([44]) the target: 53\n",
      "when input is tensor([44, 53]) the target: 56\n",
      "when input is tensor([44, 53, 56]) the target: 1\n",
      "when input is tensor([44, 53, 56,  1]) the target: 58\n",
      "when input is tensor([44, 53, 56,  1, 58]) the target: 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]) the target: 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]) the target: 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) the target: 1\n",
      "when input is tensor([52]) the target: 58\n",
      "when input is tensor([52, 58]) the target: 1\n",
      "when input is tensor([52, 58,  1]) the target: 58\n",
      "when input is tensor([52, 58,  1, 58]) the target: 46\n",
      "when input is tensor([52, 58,  1, 58, 46]) the target: 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]) the target: 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]) the target: 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) the target: 46\n",
      "when input is tensor([25]) the target: 17\n",
      "when input is tensor([25, 17]) the target: 27\n",
      "when input is tensor([25, 17, 27]) the target: 10\n",
      "when input is tensor([25, 17, 27, 10]) the target: 0\n",
      "when input is tensor([25, 17, 27, 10,  0]) the target: 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]) the target: 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]) the target: 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small size batches of inputs x and target y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"inputs\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print(\"targets\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        contex = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {contex} the target: {target}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46bf2707-0b40-4319-9348-0d93ff6992a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and target are B, T tensor\n",
    "        logits = self.token_embedding_table(idx)  #B, T, C\n",
    "\n",
    "        if targets is None:\n",
    "            loss = 0\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indecis of current contex\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)  #call forward and get prediction\n",
    "            logits = logits[:,-1, :] #becomes (B, C)\n",
    "            probs = F.softmax(logits, dim=1) #softmax to get probablities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  #(B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  #(B, T+1)\n",
    "        return idx\n",
    "            \n",
    "            \n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe02325b-79c2-4d08-9690-3d0421109691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating python optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e66b546-c7c7-4b29-95e2-f129ad8cfaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5332515239715576\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # eval the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d0e88f3-a54a-43a9-8910-e75e74d14445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "IOFinge NUCa thofes inomee:\n",
      "I Ve d tfu bemak o st r, htis g angringhe us ainlyomaroughim ry; geoat yodime istho aund.\n",
      "Vliolathe'y iowere ESTMUMyene pagginourigafomal areroneee t.\n",
      "Whingri'd houedlld hecculanoustime d,\n",
      "Myok, wivea hif h ithethe ho,\n",
      "\n",
      "Why,\n",
      "Shomy d myonefitwr, ten!LIO:\n",
      "CO:\n",
      "ORD mond ouca\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "433645fe-c3bc-4bfb-aaca-f017325f50c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1771,  1.2758],\n",
      "        [-0.5472,  0.2220],\n",
      "        [-0.5466,  1.0820],\n",
      "        [ 1.8327,  0.6423],\n",
      "        [ 0.4958,  0.4040],\n",
      "        [ 0.0217, -0.5402],\n",
      "        [ 0.9214, -0.2138],\n",
      "        [ 1.4714,  0.8060]])\n",
      "tensor([[ 0.1771,  1.2758],\n",
      "        [-0.1850,  0.7489],\n",
      "        [-0.3055,  0.8599],\n",
      "        [ 0.2290,  0.8055],\n",
      "        [ 0.2824,  0.7252],\n",
      "        [ 0.2389,  0.5143],\n",
      "        [ 0.3364,  0.4103],\n",
      "        [ 0.4783,  0.4598]])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "tril = torch.tril(torch.ones((T,T)))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "xbow = wei @ x #----> (T, T) @ (B,T,C) == broadcast ==> (B, T, T) @ (B, T, C) -->(B, T, C)\n",
    "print(x[0])\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48b0a75d-53d8-42a4-9743-52e6be052616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf63ea-aae9-416e-a85b-1d4956729222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
